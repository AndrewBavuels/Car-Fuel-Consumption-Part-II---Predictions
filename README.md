# **Car Fuel Consumption Part II - Analysis and Predictions ðŸš—ðŸ“ˆðŸ”®**

# (In working progress...)

This is the **Part II** of a project series in which I am applying **advanced analytics.** You can click on ðŸ‘‰ [Part I: Exploratory Data Analysis (EDA) Visualization with Python](https://github.com/AndrewBavuels/Car-Fuel-Consumption-Part-I), which I have already done.

Now the turn for this is **predictions with Machine Learning,** regarding Car Fuel Consumption.

![Let's Get the Party Started](https://media.giphy.com/media/lNGyr4FWfRO8S8LARn/giphy.gif)


## 1. Project description ðŸ‘‡
 
### _Part II: Predictions with Machine Learning using scikit-learn._

I am going to work on the pre-processed dataset from the first part of this project, that started by using the "Car Fuel Consumption per gas fuel type" dataset from [Kaggle](https://www.kaggle.com/datasets/anderas/car-consume/). 

#### Predictions

- Do you have any hypothesis?
- Can you make any kind of prediction: regression and/or classification?

<!-- - **Question #1:** Which gas type consumes the most? E10 or SP98?
- **Question #2:** How much is the consume?
- **Question #3:** It consumes 0.4 liters more with E10 gas, isn't it?
- **Question #4:** Which of the two fuels is cheaper, E10 or SP 98? -->

<!-- "_All these questions are answered in the notebook of this repository._" -->

![Driving Fast And Furious GIF by The Fast Saga](https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExcmtkcHMzbTJsODltamZtaDFhN3cxM2d6OTRncWVtYng3OWtkOGIzdSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/2EWa4uTH39d2NTJRGy/giphy.gif)
<!-- 
### Exploratory Data Analysis => Summary:

- **Performing data maintenance or cleaning:** Duplicates, null-values, outliers
- **String operations:** Normalize to lowercase, replacing numbers to categorical and vice-versa
- **Feature Engineering:** Merging features, such as 'consumption rate' based on distance and consumed gas
- **Relational model transformation:** For future project steps
- **Answering questions from our Exploratory Data Analysis:** The main goal of this repository -->

<!-- ### Highlights: -->




## **2. Technology stack ðŸ’»**

### Programming language:
- [Python](https://docs.python.org/3/)

### Python Libraries:
- [pandas](https://pandas.pydata.org/docs/reference/frame.html): For data manipulation and analysis.
- [numpy](https://numpy.org/doc/stable/): For mathematical operations and array manipulation.
- [matplotlib.pyplot](https://matplotlib.org/stable/contents.html): For data visualization.
- [scipy](https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.stats.skewnorm.html): For scientific and technical computing.
- [joblib](https://joblib.readthedocs.io/en/latest/): For lightweight pipelining in Python.
- [sklearn](https://scikit-learn.org/stable/): For machine learning modeling and model evaluation.
- [flask](https://flask.palletsprojects.com/en/2.0.x/): For building web applications and APIs in Python.

### Environment Setup:
1. **Python Environment Configuration**
   - Download [get-pip.py](https://bootstrap.pypa.io/get-pip.py)
   - Install pip: `python get-pip.py`
   - Install virtualenv: `python -m pip install virtualenv`
   - Create a virtual environment named `predictions_env`: `python -m virtualenv predictions_env`

2. **Activating the Virtual Environment (PowerShell)**
   ```powershell
   C:\Users\andre\cyberpunkNoMAD\Tech Skills\ML\sklearn\REPO\predictions_env> .\Scripts\Activate.ps1
   (predictions_env) PS C:\Users\andre\cyberpunkNoMAD\Tech Skills\ML\sklearn\REPO\predictions_env>

### Development tools: 
- [VSC](https://code.visualstudio.com/)
- Terminal
<!-- #### Distribution platform
- [Anaconda](https://www.anaconda.com/)

#### Computing environment
- [Jupyter Notebooks](https://jupyter.org/) -->

<!-- ## **3. Folder structure ðŸ“**
```
â””â”€â”€ project
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ raw
    â”‚   â”‚   â””â”€â”€ measurements.csv
    â”‚   â””â”€â”€ pre_processed
    â”‚   â”‚   â””â”€â”€ pre_processed_gas_df.csv
    â”œâ”€â”€ notebooks
    â”‚   â””â”€â”€ main.ipynb
    â””â”€â”€ README.md    
``` -->
## **4. Next steps ðŸ’¡**

#### Enriching the dataset

- Obtain related data by web scraping or with APIs.

#### Database

- Load the processed information into a database

###  **Contact infoðŸ“§**
For further information, reach me at andres.buelvas.diago.01@gmail.com
